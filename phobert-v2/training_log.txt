2026-02-28 23:17:09,613 [INFO] Training log â†’ /home/long/myProjects/vietnamese-news-classification-phobert/phobert-v2/training_log.txt
2026-02-28 23:17:09,746 [INFO] Using device: cuda
2026-02-28 23:17:09,746 [INFO] Loading data â€¦
2026-02-28 23:17:10,921 [INFO] Train: 50,373  Val: 16,879  Test: 16,880  Classes: 10
2026-02-28 23:17:10,921 [INFO] Label map saved â†’ /home/long/myProjects/vietnamese-news-classification-phobert/phobert-v2/label_map.json
2026-02-28 23:17:10,921 [INFO] Loading tokenizer: vinai/phobert-base-v2
2026-02-28 23:17:11,277 [INFO] HTTP Request: HEAD https://huggingface.co/vinai/phobert-base-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-28 23:17:11,290 [INFO] HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/vinai/phobert-base-v2/e2375d266bdf39c6e8e9a87af16a5da3190b0cc8/config.json "HTTP/1.1 200 OK"
2026-02-28 23:17:11,562 [INFO] HTTP Request: HEAD https://huggingface.co/vinai/phobert-base-v2/resolve/main/tokenizer_config.json "HTTP/1.1 404 Not Found"
2026-02-28 23:17:11,828 [INFO] HTTP Request: HEAD https://huggingface.co/vinai/phobert-base-v2/resolve/main/tokenizer_config.json "HTTP/1.1 404 Not Found"
2026-02-28 23:17:12,095 [INFO] HTTP Request: GET https://huggingface.co/api/models/vinai/phobert-base-v2/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 404 Not Found"
2026-02-28 23:17:12,359 [INFO] HTTP Request: GET https://huggingface.co/api/models/vinai/phobert-base-v2/tree/main?recursive=true&expand=false "HTTP/1.1 200 OK"
2026-02-28 23:17:12,621 [INFO] HTTP Request: HEAD https://huggingface.co/vinai/phobert-base-v2/resolve/main/vocab.txt "HTTP/1.1 307 Temporary Redirect"
2026-02-28 23:17:12,634 [INFO] HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/vinai/phobert-base-v2/e2375d266bdf39c6e8e9a87af16a5da3190b0cc8/vocab.txt "HTTP/1.1 200 OK"
2026-02-28 23:17:12,823 [INFO] Tokenising datasets (this may take a few minutes) â€¦
2026-02-28 23:19:01,777 [INFO] Loading model: vinai/phobert-base-v2
2026-02-28 23:19:02,112 [INFO] HTTP Request: HEAD https://huggingface.co/vinai/phobert-base-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-28 23:19:02,119 [INFO] HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/vinai/phobert-base-v2/e2375d266bdf39c6e8e9a87af16a5da3190b0cc8/config.json "HTTP/1.1 200 OK"
2026-02-28 23:19:02,594 [INFO] HTTP Request: HEAD https://huggingface.co/vinai/phobert-base-v2/resolve/main/model.safetensors "HTTP/1.1 404 Not Found"
2026-02-28 23:19:02,857 [INFO] HTTP Request: GET https://huggingface.co/api/models/vinai/phobert-base-v2 "HTTP/1.1 200 OK"
2026-02-28 23:19:03,032 [INFO] Total training steps: 15,750  Warmup steps: 1,575
2026-02-28 23:19:03,033 [INFO] ============================================================
2026-02-28 23:19:03,033 [INFO] Starting training â€¦
2026-02-28 23:19:03,033 [INFO] ============================================================
2026-02-28 23:19:03,033 [INFO] 
â”€â”€ Epoch 1/10 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
2026-02-28 23:19:03,118 [INFO] HTTP Request: GET https://huggingface.co/api/models/vinai/phobert-base-v2/commits/main "HTTP/1.1 200 OK"
2026-02-28 23:19:03,386 [INFO] HTTP Request: GET https://huggingface.co/api/models/vinai/phobert-base-v2/discussions?p=0 "HTTP/1.1 200 OK"
2026-02-28 23:19:03,668 [INFO] HTTP Request: GET https://huggingface.co/api/models/vinai/phobert-base-v2/commits/refs%2Fpr%2F3 "HTTP/1.1 200 OK"
2026-02-28 23:19:03,938 [INFO] HTTP Request: HEAD https://huggingface.co/vinai/phobert-base-v2/resolve/refs%2Fpr%2F3/model.safetensors.index.json "HTTP/1.1 404 Not Found"
2026-02-28 23:19:04,196 [INFO] HTTP Request: HEAD https://huggingface.co/vinai/phobert-base-v2/resolve/refs%2Fpr%2F3/model.safetensors "HTTP/1.1 302 Found"
2026-02-28 23:19:39,965 [INFO]   Epoch 1 | step 50/1575 | loss=2.3065 | acc=0.1263
2026-02-28 23:20:16,677 [INFO]   Epoch 1 | step 100/1575 | loss=2.2932 | acc=0.1613
2026-02-28 23:20:53,545 [INFO]   Epoch 1 | step 150/1575 | loss=2.2734 | acc=0.1969
2026-02-28 23:21:30,514 [INFO]   Epoch 1 | step 200/1575 | loss=2.2498 | acc=0.2414
2026-02-28 23:22:07,537 [INFO]   Epoch 1 | step 250/1575 | loss=2.2204 | acc=0.2886
2026-02-28 23:22:44,567 [INFO]   Epoch 1 | step 300/1575 | loss=2.1841 | acc=0.3385
2026-02-28 23:23:21,604 [INFO]   Epoch 1 | step 350/1575 | loss=2.1385 | acc=0.3857
2026-02-28 23:23:58,643 [INFO]   Epoch 1 | step 400/1575 | loss=2.0820 | acc=0.4290
2026-02-28 23:24:35,665 [INFO]   Epoch 1 | step 450/1575 | loss=2.0233 | acc=0.4631
2026-02-28 23:25:12,661 [INFO]   Epoch 1 | step 500/1575 | loss=1.9620 | acc=0.4940
2026-02-28 23:25:49,650 [INFO]   Epoch 1 | step 550/1575 | loss=1.9006 | acc=0.5209
2026-02-28 23:26:26,645 [INFO]   Epoch 1 | step 600/1575 | loss=1.8413 | acc=0.5448
2026-02-28 23:27:03,644 [INFO]   Epoch 1 | step 650/1575 | loss=1.7847 | acc=0.5662
2026-02-28 23:27:40,634 [INFO]   Epoch 1 | step 700/1575 | loss=1.7278 | acc=0.5873
2026-02-28 23:28:17,641 [INFO]   Epoch 1 | step 750/1575 | loss=1.6743 | acc=0.6055
2026-02-28 23:28:54,645 [INFO]   Epoch 1 | step 800/1575 | loss=1.6247 | acc=0.6216
2026-02-28 23:29:31,640 [INFO]   Epoch 1 | step 850/1575 | loss=1.5762 | acc=0.6370
2026-02-28 23:30:08,627 [INFO]   Epoch 1 | step 900/1575 | loss=1.5308 | acc=0.6505
2026-02-28 23:30:45,622 [INFO]   Epoch 1 | step 950/1575 | loss=1.4871 | acc=0.6634
2026-02-28 23:31:22,624 [INFO]   Epoch 1 | step 1000/1575 | loss=1.4477 | acc=0.6744
2026-02-28 23:31:59,654 [INFO]   Epoch 1 | step 1050/1575 | loss=1.4090 | acc=0.6851
2026-02-28 23:32:36,654 [INFO]   Epoch 1 | step 1100/1575 | loss=1.3742 | acc=0.6943
2026-02-28 23:33:13,656 [INFO]   Epoch 1 | step 1150/1575 | loss=1.3402 | acc=0.7029
2026-02-28 23:33:50,655 [INFO]   Epoch 1 | step 1200/1575 | loss=1.3075 | acc=0.7112
2026-02-28 23:34:27,657 [INFO]   Epoch 1 | step 1250/1575 | loss=1.2764 | acc=0.7191
2026-02-28 23:35:04,652 [INFO]   Epoch 1 | step 1300/1575 | loss=1.2489 | acc=0.7252
2026-02-28 23:35:41,638 [INFO]   Epoch 1 | step 1350/1575 | loss=1.2212 | acc=0.7318
2026-02-28 23:36:18,633 [INFO]   Epoch 1 | step 1400/1575 | loss=1.1945 | acc=0.7379
2026-02-28 23:36:55,617 [INFO]   Epoch 1 | step 1450/1575 | loss=1.1685 | acc=0.7441
2026-02-28 23:37:32,605 [INFO]   Epoch 1 | step 1500/1575 | loss=1.1445 | acc=0.7494
2026-02-28 23:38:09,587 [INFO]   Epoch 1 | step 1550/1575 | loss=1.1216 | acc=0.7544
2026-02-28 23:38:27,517 [INFO]   Epoch 1 | step 1575/1575 | loss=1.1110 | acc=0.7566
2026-02-28 23:40:40,270 [INFO]   [Summary] train_loss=1.1110  train_acc=0.7566 | val_loss=0.4572  val_acc=0.8888  val_precision=0.8928  val_recall=0.8888  val_f1=0.8891 | time=1297.2s
2026-02-28 23:40:41,002 [INFO]   Best model checkpoint saved â†’ /home/long/myProjects/vietnamese-news-classification-phobert/phobert-v2/best_model
2026-02-28 23:40:41,002 [INFO] 
â”€â”€ Epoch 2/10 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
2026-02-28 23:41:18,105 [INFO]   Epoch 2 | step 50/1575 | loss=0.3693 | acc=0.9225
2026-02-28 23:41:55,104 [INFO]   Epoch 2 | step 100/1575 | loss=0.3857 | acc=0.9163
2026-02-28 23:42:32,113 [INFO]   Epoch 2 | step 150/1575 | loss=0.3939 | acc=0.9117
2026-02-28 23:43:09,106 [INFO]   Epoch 2 | step 200/1575 | loss=0.3905 | acc=0.9123
2026-02-28 23:43:46,107 [INFO]   Epoch 2 | step 250/1575 | loss=0.3860 | acc=0.9131
2026-02-28 23:44:23,099 [INFO]   Epoch 2 | step 300/1575 | loss=0.3847 | acc=0.9117
2026-02-28 23:45:00,084 [INFO]   Epoch 2 | step 350/1575 | loss=0.3800 | acc=0.9121
2026-02-28 23:45:37,075 [INFO]   Epoch 2 | step 400/1575 | loss=0.3752 | acc=0.9121
2026-02-28 23:46:14,075 [INFO]   Epoch 2 | step 450/1575 | loss=0.3748 | acc=0.9114
2026-02-28 23:46:51,076 [INFO]   Epoch 2 | step 500/1575 | loss=0.3700 | acc=0.9119
2026-02-28 23:47:28,096 [INFO]   Epoch 2 | step 550/1575 | loss=0.3644 | acc=0.9128
2026-02-28 23:48:05,109 [INFO]   Epoch 2 | step 600/1575 | loss=0.3616 | acc=0.9130
2026-02-28 23:48:42,101 [INFO]   Epoch 2 | step 650/1575 | loss=0.3580 | acc=0.9137
2026-02-28 23:49:19,101 [INFO]   Epoch 2 | step 700/1575 | loss=0.3539 | acc=0.9141
2026-02-28 23:49:56,088 [INFO]   Epoch 2 | step 750/1575 | loss=0.3508 | acc=0.9142
2026-02-28 23:50:33,078 [INFO]   Epoch 2 | step 800/1575 | loss=0.3470 | acc=0.9147
2026-02-28 23:51:10,063 [INFO]   Epoch 2 | step 850/1575 | loss=0.3442 | acc=0.9153
2026-02-28 23:51:47,054 [INFO]   Epoch 2 | step 900/1575 | loss=0.3413 | acc=0.9156
2026-02-28 23:52:24,044 [INFO]   Epoch 2 | step 950/1575 | loss=0.3375 | acc=0.9166
2026-02-28 23:53:01,031 [INFO]   Epoch 2 | step 1000/1575 | loss=0.3369 | acc=0.9163
2026-02-28 23:53:38,018 [INFO]   Epoch 2 | step 1050/1575 | loss=0.3338 | acc=0.9167
2026-02-28 23:54:15,008 [INFO]   Epoch 2 | step 1100/1575 | loss=0.3312 | acc=0.9174
2026-02-28 23:54:51,994 [INFO]   Epoch 2 | step 1150/1575 | loss=0.3286 | acc=0.9179
2026-02-28 23:55:28,983 [INFO]   Epoch 2 | step 1200/1575 | loss=0.3267 | acc=0.9180
2026-02-28 23:56:05,982 [INFO]   Epoch 2 | step 1250/1575 | loss=0.3247 | acc=0.9181
2026-02-28 23:56:42,985 [INFO]   Epoch 2 | step 1300/1575 | loss=0.3218 | acc=0.9187
2026-02-28 23:57:19,987 [INFO]   Epoch 2 | step 1350/1575 | loss=0.3195 | acc=0.9191
2026-02-28 23:57:56,985 [INFO]   Epoch 2 | step 1400/1575 | loss=0.3181 | acc=0.9193
2026-02-28 23:58:33,987 [INFO]   Epoch 2 | step 1450/1575 | loss=0.3165 | acc=0.9194
2026-02-28 23:59:10,989 [INFO]   Epoch 2 | step 1500/1575 | loss=0.3147 | acc=0.9195
2026-02-28 23:59:47,999 [INFO]   Epoch 2 | step 1550/1575 | loss=0.3135 | acc=0.9195
2026-03-01 00:00:05,924 [INFO]   Epoch 2 | step 1575/1575 | loss=0.3132 | acc=0.9195
2026-03-01 00:02:18,773 [INFO]   [Summary] train_loss=0.3132  train_acc=0.9195 | val_loss=0.3292  val_acc=0.9030  val_precision=0.9069  val_recall=0.9030  val_f1=0.9034 | time=1297.8s
2026-03-01 00:02:20,008 [INFO]   Best model checkpoint saved â†’ /home/long/myProjects/vietnamese-news-classification-phobert/phobert-v2/best_model
2026-03-01 00:02:20,008 [INFO] 
â”€â”€ Epoch 3/10 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
2026-03-01 00:02:57,137 [INFO]   Epoch 3 | step 50/1575 | loss=0.2085 | acc=0.9413
2026-03-01 00:03:34,117 [INFO]   Epoch 3 | step 100/1575 | loss=0.2241 | acc=0.9366
2026-03-01 00:04:11,105 [INFO]   Epoch 3 | step 150/1575 | loss=0.2202 | acc=0.9377
2026-03-01 00:04:48,097 [INFO]   Epoch 3 | step 200/1575 | loss=0.2120 | acc=0.9408
2026-03-01 00:05:25,084 [INFO]   Epoch 3 | step 250/1575 | loss=0.2152 | acc=0.9410
2026-03-01 00:06:02,082 [INFO]   Epoch 3 | step 300/1575 | loss=0.2159 | acc=0.9410
2026-03-01 00:06:39,081 [INFO]   Epoch 3 | step 350/1575 | loss=0.2140 | acc=0.9416
2026-03-01 00:07:16,070 [INFO]   Epoch 3 | step 400/1575 | loss=0.2166 | acc=0.9406
2026-03-01 00:07:53,065 [INFO]   Epoch 3 | step 450/1575 | loss=0.2180 | acc=0.9403
2026-03-01 00:08:30,069 [INFO]   Epoch 3 | step 500/1575 | loss=0.2158 | acc=0.9411
2026-03-01 00:09:07,054 [INFO]   Epoch 3 | step 550/1575 | loss=0.2138 | acc=0.9414
2026-03-01 00:09:44,041 [INFO]   Epoch 3 | step 600/1575 | loss=0.2138 | acc=0.9411
2026-03-01 00:10:21,033 [INFO]   Epoch 3 | step 650/1575 | loss=0.2154 | acc=0.9405
2026-03-01 00:10:58,020 [INFO]   Epoch 3 | step 700/1575 | loss=0.2155 | acc=0.9402
2026-03-01 00:11:35,038 [INFO]   Epoch 3 | step 750/1575 | loss=0.2146 | acc=0.9407
2026-03-01 00:12:12,044 [INFO]   Epoch 3 | step 800/1575 | loss=0.2136 | acc=0.9412
2026-03-01 00:12:49,052 [INFO]   Epoch 3 | step 850/1575 | loss=0.2121 | acc=0.9415
2026-03-01 00:13:26,036 [INFO]   Epoch 3 | step 900/1575 | loss=0.2126 | acc=0.9413
2026-03-01 00:14:03,029 [INFO]   Epoch 3 | step 950/1575 | loss=0.2109 | acc=0.9414
2026-03-01 00:14:40,051 [INFO]   Epoch 3 | step 1000/1575 | loss=0.2113 | acc=0.9412
2026-03-01 00:15:17,058 [INFO]   Epoch 3 | step 1050/1575 | loss=0.2122 | acc=0.9407
2026-03-01 00:15:54,079 [INFO]   Epoch 3 | step 1100/1575 | loss=0.2120 | acc=0.9406
2026-03-01 00:16:31,095 [INFO]   Epoch 3 | step 1150/1575 | loss=0.2120 | acc=0.9403
2026-03-01 00:17:08,087 [INFO]   Epoch 3 | step 1200/1575 | loss=0.2123 | acc=0.9400
2026-03-01 00:17:45,074 [INFO]   Epoch 3 | step 1250/1575 | loss=0.2126 | acc=0.9398
2026-03-01 00:18:22,059 [INFO]   Epoch 3 | step 1300/1575 | loss=0.2131 | acc=0.9396
2026-03-01 00:18:59,055 [INFO]   Epoch 3 | step 1350/1575 | loss=0.2132 | acc=0.9395
2026-03-01 00:19:36,057 [INFO]   Epoch 3 | step 1400/1575 | loss=0.2133 | acc=0.9394
2026-03-01 00:20:13,047 [INFO]   Epoch 3 | step 1450/1575 | loss=0.2130 | acc=0.9393
2026-03-01 00:20:50,036 [INFO]   Epoch 3 | step 1500/1575 | loss=0.2126 | acc=0.9392
2026-03-01 00:21:27,024 [INFO]   Epoch 3 | step 1550/1575 | loss=0.2122 | acc=0.9393
2026-03-01 00:21:44,941 [INFO]   Epoch 3 | step 1575/1575 | loss=0.2124 | acc=0.9392
2026-03-01 00:23:57,748 [INFO]   [Summary] train_loss=0.2124  train_acc=0.9392 | val_loss=0.2952  val_acc=0.9144  val_precision=0.9150  val_recall=0.9144  val_f1=0.9141 | time=1297.7s
2026-03-01 00:23:58,962 [INFO]   Best model checkpoint saved â†’ /home/long/myProjects/vietnamese-news-classification-phobert/phobert-v2/best_model
2026-03-01 00:23:58,963 [INFO] 
â”€â”€ Epoch 4/10 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
2026-03-01 00:24:36,078 [INFO]   Epoch 4 | step 50/1575 | loss=0.1462 | acc=0.9569
2026-03-01 00:25:13,074 [INFO]   Epoch 4 | step 100/1575 | loss=0.1537 | acc=0.9544
2026-03-01 00:25:50,060 [INFO]   Epoch 4 | step 150/1575 | loss=0.1566 | acc=0.9537
2026-03-01 00:26:27,049 [INFO]   Epoch 4 | step 200/1575 | loss=0.1586 | acc=0.9545
2026-03-01 00:27:04,034 [INFO]   Epoch 4 | step 250/1575 | loss=0.1582 | acc=0.9549
2026-03-01 00:27:41,024 [INFO]   Epoch 4 | step 300/1575 | loss=0.1550 | acc=0.9557
2026-03-01 00:28:18,012 [INFO]   Epoch 4 | step 350/1575 | loss=0.1557 | acc=0.9552
2026-03-01 00:28:55,002 [INFO]   Epoch 4 | step 400/1575 | loss=0.1577 | acc=0.9549
2026-03-01 00:29:31,990 [INFO]   Epoch 4 | step 450/1575 | loss=0.1614 | acc=0.9536
2026-03-01 00:30:08,977 [INFO]   Epoch 4 | step 500/1575 | loss=0.1603 | acc=0.9537
2026-03-01 00:30:45,965 [INFO]   Epoch 4 | step 550/1575 | loss=0.1628 | acc=0.9530
2026-03-01 00:31:22,946 [INFO]   Epoch 4 | step 600/1575 | loss=0.1615 | acc=0.9533
2026-03-01 00:31:59,935 [INFO]   Epoch 4 | step 650/1575 | loss=0.1607 | acc=0.9537
2026-03-01 00:32:36,907 [INFO]   Epoch 4 | step 700/1575 | loss=0.1596 | acc=0.9537
2026-03-01 00:33:13,894 [INFO]   Epoch 4 | step 750/1575 | loss=0.1597 | acc=0.9538
2026-03-01 00:33:50,885 [INFO]   Epoch 4 | step 800/1575 | loss=0.1568 | acc=0.9547
2026-03-01 00:34:27,871 [INFO]   Epoch 4 | step 850/1575 | loss=0.1589 | acc=0.9542
2026-03-01 00:35:04,857 [INFO]   Epoch 4 | step 900/1575 | loss=0.1612 | acc=0.9535
2026-03-01 00:35:41,847 [INFO]   Epoch 4 | step 950/1575 | loss=0.1608 | acc=0.9535
2026-03-01 00:36:18,834 [INFO]   Epoch 4 | step 1000/1575 | loss=0.1612 | acc=0.9536
2026-03-01 00:36:55,820 [INFO]   Epoch 4 | step 1050/1575 | loss=0.1614 | acc=0.9537
2026-03-01 00:37:32,806 [INFO]   Epoch 4 | step 1100/1575 | loss=0.1606 | acc=0.9541
2026-03-01 00:38:09,796 [INFO]   Epoch 4 | step 1150/1575 | loss=0.1607 | acc=0.9540
2026-03-01 00:38:46,791 [INFO]   Epoch 4 | step 1200/1575 | loss=0.1621 | acc=0.9537
2026-03-01 00:39:23,773 [INFO]   Epoch 4 | step 1250/1575 | loss=0.1637 | acc=0.9531
2026-03-01 00:40:00,756 [INFO]   Epoch 4 | step 1300/1575 | loss=0.1639 | acc=0.9531
2026-03-01 00:40:37,747 [INFO]   Epoch 4 | step 1350/1575 | loss=0.1635 | acc=0.9534
2026-03-01 00:41:14,745 [INFO]   Epoch 4 | step 1400/1575 | loss=0.1640 | acc=0.9532
2026-03-01 00:41:51,724 [INFO]   Epoch 4 | step 1450/1575 | loss=0.1639 | acc=0.9532
2026-03-01 00:42:28,713 [INFO]   Epoch 4 | step 1500/1575 | loss=0.1636 | acc=0.9532
2026-03-01 00:43:05,703 [INFO]   Epoch 4 | step 1550/1575 | loss=0.1631 | acc=0.9533
2026-03-01 00:43:23,615 [INFO]   Epoch 4 | step 1575/1575 | loss=0.1635 | acc=0.9532
2026-03-01 00:45:36,451 [INFO]   [Summary] train_loss=0.1635  train_acc=0.9532 | val_loss=0.3163  val_acc=0.9162  val_precision=0.9181  val_recall=0.9162  val_f1=0.9163 | time=1297.5s
2026-03-01 00:45:36,452 [INFO] 
â”€â”€ Epoch 5/10 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
2026-03-01 00:46:13,539 [INFO]   Epoch 5 | step 50/1575 | loss=0.1084 | acc=0.9719
2026-03-01 00:46:50,526 [INFO]   Epoch 5 | step 100/1575 | loss=0.1243 | acc=0.9672
2026-03-01 00:47:27,516 [INFO]   Epoch 5 | step 150/1575 | loss=0.1201 | acc=0.9677
2026-03-01 00:48:04,501 [INFO]   Epoch 5 | step 200/1575 | loss=0.1297 | acc=0.9656
2026-03-01 00:48:41,492 [INFO]   Epoch 5 | step 250/1575 | loss=0.1334 | acc=0.9644
2026-03-01 00:49:18,484 [INFO]   Epoch 5 | step 300/1575 | loss=0.1321 | acc=0.9647
2026-03-01 00:49:55,475 [INFO]   Epoch 5 | step 350/1575 | loss=0.1307 | acc=0.9651
2026-03-01 00:50:32,482 [INFO]   Epoch 5 | step 400/1575 | loss=0.1327 | acc=0.9647
2026-03-01 00:51:09,472 [INFO]   Epoch 5 | step 450/1575 | loss=0.1361 | acc=0.9635
2026-03-01 00:51:46,457 [INFO]   Epoch 5 | step 500/1575 | loss=0.1360 | acc=0.9629
2026-03-01 00:52:23,444 [INFO]   Epoch 5 | step 550/1575 | loss=0.1342 | acc=0.9635
2026-03-01 00:53:00,436 [INFO]   Epoch 5 | step 600/1575 | loss=0.1355 | acc=0.9634
2026-03-01 00:53:37,441 [INFO]   Epoch 5 | step 650/1575 | loss=0.1338 | acc=0.9637
2026-03-01 00:54:14,445 [INFO]   Epoch 5 | step 700/1575 | loss=0.1344 | acc=0.9632
2026-03-01 00:54:51,435 [INFO]   Epoch 5 | step 750/1575 | loss=0.1356 | acc=0.9629
2026-03-01 00:55:28,425 [INFO]   Epoch 5 | step 800/1575 | loss=0.1347 | acc=0.9633
2026-03-01 00:56:05,439 [INFO]   Epoch 5 | step 850/1575 | loss=0.1356 | acc=0.9630
2026-03-01 00:56:42,440 [INFO]   Epoch 5 | step 900/1575 | loss=0.1351 | acc=0.9632
2026-03-01 00:57:19,448 [INFO]   Epoch 5 | step 950/1575 | loss=0.1344 | acc=0.9633
2026-03-01 00:57:56,451 [INFO]   Epoch 5 | step 1000/1575 | loss=0.1337 | acc=0.9633
2026-03-01 00:58:33,467 [INFO]   Epoch 5 | step 1050/1575 | loss=0.1332 | acc=0.9635
2026-03-01 00:59:10,471 [INFO]   Epoch 5 | step 1100/1575 | loss=0.1321 | acc=0.9639
2026-03-01 00:59:47,457 [INFO]   Epoch 5 | step 1150/1575 | loss=0.1317 | acc=0.9640
2026-03-01 01:00:24,445 [INFO]   Epoch 5 | step 1200/1575 | loss=0.1319 | acc=0.9639
2026-03-01 01:01:01,448 [INFO]   Epoch 5 | step 1250/1575 | loss=0.1311 | acc=0.9640
2026-03-01 01:01:38,444 [INFO]   Epoch 5 | step 1300/1575 | loss=0.1307 | acc=0.9641
2026-03-01 01:02:15,430 [INFO]   Epoch 5 | step 1350/1575 | loss=0.1303 | acc=0.9641
2026-03-01 01:02:52,418 [INFO]   Epoch 5 | step 1400/1575 | loss=0.1304 | acc=0.9642
2026-03-01 01:03:29,405 [INFO]   Epoch 5 | step 1450/1575 | loss=0.1303 | acc=0.9643
2026-03-01 01:04:06,401 [INFO]   Epoch 5 | step 1500/1575 | loss=0.1311 | acc=0.9642
2026-03-01 01:04:43,391 [INFO]   Epoch 5 | step 1550/1575 | loss=0.1323 | acc=0.9639
2026-03-01 01:05:01,310 [INFO]   Epoch 5 | step 1575/1575 | loss=0.1320 | acc=0.9638
2026-03-01 01:07:14,065 [INFO]   [Summary] train_loss=0.1320  train_acc=0.9638 | val_loss=0.3247  val_acc=0.9219  val_precision=0.9227  val_recall=0.9219  val_f1=0.9218 | time=1297.6s
2026-03-01 01:07:14,066 [INFO] 
â”€â”€ Epoch 6/10 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
2026-03-01 01:07:51,149 [INFO]   Epoch 6 | step 50/1575 | loss=0.0996 | acc=0.9725
2026-03-01 01:08:28,142 [INFO]   Epoch 6 | step 100/1575 | loss=0.0923 | acc=0.9747
2026-03-01 01:09:05,128 [INFO]   Epoch 6 | step 150/1575 | loss=0.1026 | acc=0.9708
2026-03-01 01:09:42,098 [INFO]   Epoch 6 | step 200/1575 | loss=0.1026 | acc=0.9716
2026-03-01 01:10:19,084 [INFO]   Epoch 6 | step 250/1575 | loss=0.1048 | acc=0.9708
2026-03-01 01:10:56,073 [INFO]   Epoch 6 | step 300/1575 | loss=0.1043 | acc=0.9704
2026-03-01 01:11:33,058 [INFO]   Epoch 6 | step 350/1575 | loss=0.1029 | acc=0.9709
2026-03-01 01:12:10,027 [INFO]   Epoch 6 | step 400/1575 | loss=0.1046 | acc=0.9708
2026-03-01 01:12:47,015 [INFO]   Epoch 6 | step 450/1575 | loss=0.1059 | acc=0.9708
2026-03-01 01:13:24,011 [INFO]   Epoch 6 | step 500/1575 | loss=0.1093 | acc=0.9701
2026-03-01 01:14:00,999 [INFO]   Epoch 6 | step 550/1575 | loss=0.1079 | acc=0.9706
2026-03-01 01:14:37,983 [INFO]   Epoch 6 | step 600/1575 | loss=0.1049 | acc=0.9714
2026-03-01 01:15:14,965 [INFO]   Epoch 6 | step 650/1575 | loss=0.1050 | acc=0.9714
2026-03-01 01:15:51,960 [INFO]   Epoch 6 | step 700/1575 | loss=0.1057 | acc=0.9710
2026-03-01 01:16:28,951 [INFO]   Epoch 6 | step 750/1575 | loss=0.1058 | acc=0.9710
2026-03-01 01:17:05,940 [INFO]   Epoch 6 | step 800/1575 | loss=0.1057 | acc=0.9711
2026-03-01 01:17:42,927 [INFO]   Epoch 6 | step 850/1575 | loss=0.1057 | acc=0.9711
2026-03-01 01:18:19,915 [INFO]   Epoch 6 | step 900/1575 | loss=0.1044 | acc=0.9717
2026-03-01 01:18:56,907 [INFO]   Epoch 6 | step 950/1575 | loss=0.1037 | acc=0.9719
2026-03-01 01:19:33,912 [INFO]   Epoch 6 | step 1000/1575 | loss=0.1054 | acc=0.9718
2026-03-01 01:20:10,919 [INFO]   Epoch 6 | step 1050/1575 | loss=0.1063 | acc=0.9716
2026-03-01 01:20:47,911 [INFO]   Epoch 6 | step 1100/1575 | loss=0.1069 | acc=0.9715
2026-03-01 01:21:24,920 [INFO]   Epoch 6 | step 1150/1575 | loss=0.1068 | acc=0.9717
2026-03-01 01:22:01,913 [INFO]   Epoch 6 | step 1200/1575 | loss=0.1071 | acc=0.9716
2026-03-01 01:22:38,935 [INFO]   Epoch 6 | step 1250/1575 | loss=0.1073 | acc=0.9716
2026-03-01 01:23:15,930 [INFO]   Epoch 6 | step 1300/1575 | loss=0.1058 | acc=0.9719
2026-03-01 01:23:52,913 [INFO]   Epoch 6 | step 1350/1575 | loss=0.1064 | acc=0.9718
2026-03-01 01:24:29,897 [INFO]   Epoch 6 | step 1400/1575 | loss=0.1062 | acc=0.9718
2026-03-01 01:25:06,889 [INFO]   Epoch 6 | step 1450/1575 | loss=0.1065 | acc=0.9717
2026-03-01 01:25:43,877 [INFO]   Epoch 6 | step 1500/1575 | loss=0.1063 | acc=0.9717
2026-03-01 01:26:20,862 [INFO]   Epoch 6 | step 1550/1575 | loss=0.1063 | acc=0.9717
2026-03-01 01:26:38,778 [INFO]   Epoch 6 | step 1575/1575 | loss=0.1053 | acc=0.9719
2026-03-01 01:28:51,566 [INFO]   [Summary] train_loss=0.1053  train_acc=0.9719 | val_loss=0.3546  val_acc=0.9212  val_precision=0.9214  val_recall=0.9212  val_f1=0.9210 | time=1297.5s
2026-03-01 01:28:51,566 [INFO] 
ðŸ›‘ Early stopping triggered after epoch 6 (no val_loss improvement for 3 consecutive epochs).
2026-03-01 01:28:51,566 [INFO] 
Saving final model â†’ /home/long/myProjects/vietnamese-news-classification-phobert/phobert-v2
2026-03-01 01:28:52,292 [INFO] Training history â†’ /home/long/myProjects/vietnamese-news-classification-phobert/phobert-v2/training_history.csv
2026-03-01 01:28:52,292 [INFO] 
Evaluating on test set â€¦
2026-03-01 01:31:05,302 [INFO]   Test loss: 0.3053  Test acc: 0.9132  Test precision: 0.9138  Test recall: 0.9132  Test F1: 0.9127
2026-03-01 01:31:05,953 [INFO]   Confusion matrix saved â†’ /home/long/myProjects/vietnamese-news-classification-phobert/phobert-v2/confusion_matrix.png
2026-03-01 01:31:05,953 [INFO] ============================================================
2026-03-01 01:31:05,954 [INFO] Training complete.
2026-03-01 01:31:05,954 [INFO]   Best model:  /home/long/myProjects/vietnamese-news-classification-phobert/phobert-v2/best_model
2026-03-01 01:31:05,954 [INFO]   Final model: /home/long/myProjects/vietnamese-news-classification-phobert/phobert-v2
2026-03-01 01:31:05,954 [INFO]   History:     /home/long/myProjects/vietnamese-news-classification-phobert/phobert-v2/training_history.csv
2026-03-01 01:31:05,954 [INFO] ============================================================
